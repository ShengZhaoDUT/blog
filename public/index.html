<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>ShengZhao&#39;s Blog</title>
  <meta name="author" content="ShengZhao">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="ShengZhao&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="ShengZhao&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">ShengZhao&#39;s Blog</a></h1>
  <h2><a href="/">专注分布式技术</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-01-12T07:48:35.000Z"><a href="/2016/01/12/2PC/">2016-01-12</a></time>
      
      
  
    <h1 class="title"><a href="/2016/01/12/2PC/">两阶段提交协议</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="u4ECB_u7ECD"><a href="#u4ECB_u7ECD" class="headerlink" title="介绍"></a>介绍</h2><p>首先用一张图说明2PC所处的背景知识</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1444386-2e2a57fc94ce22b5.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="事务的演进"></p>
<ul>
<li>左边的图表明在同一台机器上，几个进程要完成一个事务，由于在同一台机器上共享内存，只有进程间的同步互斥操作，不存在消息的传递。</li>
<li>中间的图表明客户端进程要完成一个事务（多个客户端之间也有自己要完成的并发事务），但是事务（Lock）的管理由一台服务器管理，这里只存在客户端和锁服务之间的消息传递，不存在锁服务器之间的一致。</li>
<li>中间的情况必然存在Lock服务器的不安全性，因此需要backup机器，而多个机器之间需要相互同步（当然不理解成备份机，理解成一个事务就是要跨server执行也是可以的）。这种情况下就需要用到分布式环境下的事务提交协议或者consensus协议。</li>
</ul>
<p>在事务进行过程中，除了参与者在加入分布式事务时通知协调者之外，协调者和参与者之间没有其他通信。客户的事务提交（或放弃）请求直接发送给协调者。如果客户请求abortTransaction，或者事务已经被某个参与者放弃，那么协调者可以立即通知所有参与者放弃事务。只有当客户请求协调者提交事务时，两阶段提交协议才开始使用。</p>
<h4 id="u7EF4_u57FA_u767E_u79D1_u7684_u89E3_u91CA_uFF1A"><a href="#u7EF4_u57FA_u767E_u79D1_u7684_u89E3_u91CA_uFF1A" class="headerlink" title="维基百科的解释："></a>维基百科的解释：</h4><p>为了使基于<a href="https://zh.wikipedia.org/w/index.php?title=%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F&amp;action=edit&amp;redlink=1" target="_blank" rel="external">分布式系统</a>架构下的所有节点在进行事务提交时保持一致性而设计的一种算法。通常，<strong>二阶段提交</strong>也被称为是一种<strong>协议</strong>(Protocol)。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的[ACID]特性，需要引入一个作为<strong>协调者</strong>的组件来统一掌控所有节点(称作<strong>参与者</strong>)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。<br>因此两阶段提交协议也可以认为是一种consensus问题的解决方式</p>
<h4 id="u89D2_u8272_uFF1A"><a href="#u89D2_u8272_uFF1A" class="headerlink" title="角色："></a>角色：</h4><ul>
<li>客户端：请求发起事务的一方</li>
<li>协调者：决定事务能够commit或者abort的中间节点，顾名思义，协调其他参与者的情况</li>
<li>参与者：参与客户端提交的决议（对为什么要有多参与者，我觉得有以下两种场景可以理解：1 为了保证系统可靠，需要有replication，因此各个备份节点如何达成一致？ 2 典型的银行事务。一个账号给另一个账号汇钱，但是这两个账号不在同一台机器，不同的机器就是不同的参与者）</li>
</ul>
<h2 id="u7B97_u6CD5"><a href="#u7B97_u6CD5" class="headerlink" title="算法"></a>算法</h2><h4 id="u7B97_u6CD5_u5047_u8BBE"><a href="#u7B97_u6CD5_u5047_u8BBE" class="headerlink" title="算法假设"></a>算法假设</h4><ul>
<li>该分布式系统中，存在一个节点作为<strong>协调者</strong>(Coordinator)，其他节点作为<strong>参与者</strong>(Cohorts)。且节点之间可以进行网络通信。</li>
<li>所有节点都采用预写式日志，且日志被写入后即被保持在可靠的存储设备上，即使节点损坏不会导致日志数据的消失。</li>
<li>所有节点不会永久性损坏，即使损坏后仍然可以恢复。<h4 id="u7B97_u6CD5_u63CF_u8FF0"><a href="#u7B97_u6CD5_u63CF_u8FF0" class="headerlink" title="算法描述"></a>算法描述</h4>第一阶段：</li>
<li>协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。</li>
<li>参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。</li>
<li>各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。<br>第二阶段：<br>成功，当协调者节点从所有参与者节点获得的相应消息都为”同意”时：</li>
<li>协调者节点向所有参与者节点发出”正式提交”的请求。</li>
<li>参与者节点正式完成操作，并释放在整个事务期间内占用的资源。</li>
<li>参与者节点向协调者节点发送”完成”消息。</li>
<li>协调者节点收到所有参与者节点反馈的”完成”消息后，完成事务。<br>失败，如果任一参与者节点在第一阶段返回的响应消息为”终止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：</li>
<li>协调者节点向所有参与者节点发出”回滚操作”的请求。</li>
<li>参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。</li>
<li>参与者节点向协调者节点发送”回滚完成”消息。</li>
<li>协调者节点收到所有参与者节点反馈的”回滚完成”消息后，取消事务。</li>
</ul>
<h2 id="u5B58_u5728_u7684_u7F3A_u9677"><a href="#u5B58_u5728_u7684_u7F3A_u9677" class="headerlink" title="存在的缺陷"></a>存在的缺陷</h2><p>在分布式系统的设计里面，一致性和可用性往往存在矛盾，如果要求所有的机器都要完成一件事情才能认为完成，那么这样的系统必然存在可用性的问题。假设当一台机器发生crash或者消息不能够及时传递，就会导致整个系统阻塞。2PC就是一种典型的阻塞式协议（在除第一个极端的每一个通信阶段都会有阻塞的情况发生），解决阻塞的最好办法就是引入超时机制。</p>
<ul>
<li>阶段1中协调者要等待所有的参与者反馈，此时如果有参与者没有反馈（消息丢失，网络分区，进程crash），则协调者将一直等待下去。加入超时判断时候，一定时间内没有收集齐则发送消息认定操作失败，全局广播取消事务。</li>
<li>协调者无法服务，这个时候参与者有两种情况。此时参与者会一直阻塞，等待协调者回复。此时解决办法通常都是重新选举一个协调者。</li>
<li>现在重新考虑协调者无法服务（协调者crash，网络分区），如果是第二阶段，协调者已经发出表决之后的决定（commit or abort）之后发生错误，此时参与者可以询问其他参与者Q来决定自己的状态：1. 如果Q已经commit，则自己可以放心commit。 2. 如果Q已经abort，则自己可以放心aboirt。 3. 如果Q处于INIT状态（就是阶段1刚开始的情况），此时表明协调者在阶段1发送投票请求的时候crash或者是协调者和Q之间存在通信故障，则此时可以说明协调者不可能commit，则自己可以放心标记为abort即可。 4. 如果Q与自己状态相同，则需要询问其他参与者。</li>
<li>另外我们发现如果出现网络分区，可能会出现脑裂现象，此时无法确定谁才是真正的协调者。</li>
</ul>
<p>下图是《大数据日知录》提供的2PC有限状态机<br><img src="http://upload-images.jianshu.io/upload_images/1444386-51fa18d9d6df4059.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="IMG_0039.JPG"></p>
<p>正因为2PC存在问题，所以之后有3PC和Paxos的方式</p>
<p>感觉分布式事务也可以理解成广义的consensus问题，其实就是多个机器要完成一件All or noting的事情，多个机器的状态必然是要同步的。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-01-12T07:44:47.000Z"><a href="/2016/01/12/paxos/">2016-01-12</a></time>
      
      
  
    <h1 class="title"><a href="/2016/01/12/paxos/">Paxos 算法</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="u5F15_u8A00"><a href="#u5F15_u8A00" class="headerlink" title="引言"></a>引言</h2><p>有人说分布式系统里面就是可用性，可扩展性，可靠性，一致性，性能等各种特性之间的trade off，没有一个功能是能将分布式所有的问题都解决好，只是根据自己现有的应用场景，对特定的几点进行优化。但是Paxos堪称是完美的算法，基本上没有特殊的限制条件，能够很方便的应用并且已经得到Google，Micosoft和开源社区的证明。至于Paxos的段子就不多说了，很多学习Paxos的人必然会看到各种Paxos的传奇来历。</p>
<h4 id="Paxos_u8981_u89E3_u51B3_u7684_u95EE_u9898"><a href="#Paxos_u8981_u89E3_u51B3_u7684_u95EE_u9898" class="headerlink" title="Paxos要解决的问题"></a>Paxos要解决的问题</h4><p>Paxos的一个典型应用场景是在RSM（replicated state machine）中，保证每个副本都执行相同顺序的操作，使所有的副本保持一致。归根结题，Paxos保证在一次Paxos实例中，确定唯一的一个值，而且这个值能够被持久化应用与其他进程。</p>
<h4 id="u57FA_u672C_u8981_u6C42"><a href="#u57FA_u672C_u8981_u6C42" class="headerlink" title="基本要求"></a>基本要求</h4><p>分布式系统能够正常运行的基本要求通常是Safety &amp; Liveness</p>
<ul>
<li>Only a value that has been proposed may be chosen</li>
<li>Only a single value is chosen</li>
<li>A process never learns that a value has been chosen unless it actually has been.</li>
<li>Ensure that some proposed value is eventually chosen and, if a value has been chosen, then a process can eventually learn the value</li>
<li>Ensure the progress of the system, avoid deadlock</li>
</ul>
<h4 id="u524D_u63D0_u5047_u8BBE_uFF08_u8981_u6C42_uFF09"><a href="#u524D_u63D0_u5047_u8BBE_uFF08_u8981_u6C42_uFF09" class="headerlink" title="前提假设（要求）"></a>前提假设（要求）</h4><p>Paxos建立在一个异步网络，没有Byzantine问题的模型中。</p>
<ul>
<li>处理器：处理器之间不同步，可能会遇到错误，但是可以提供持久化的存储来记录状态。</li>
<li>网络：各节点之间可以相互通信，但是可能遇到丢包，乱序，重发等问题。</li>
</ul>
<h2 id="u7B97_u6CD5"><a href="#u7B97_u6CD5" class="headerlink" title="算法"></a>算法</h2><h4 id="u89D2_u8272_uFF1A"><a href="#u89D2_u8272_uFF1A" class="headerlink" title="角色："></a>角色：</h4><ul>
<li>Client：向分布式系统发起请求并等待回复，系统内部的实现对于clien是一个黑盒，请求具体发给谁，消息流是什么样的，client并不清楚。</li>
<li>Acceptor：用于chosen value时投票决议。</li>
<li>Proposer：负责将client的请求封装交给系统决议。</li>
<li>Learner：learner代表了用户的复制参数，一旦proposer的提案被采纳，则learner就可以学习相应的结果。<br>为了能够保证整个Paxos协议的progress（不形成死锁且效率提高），他是一个特殊的proposer，client都把request发给这个proposer，当系统中存在一个proposer，没有冲突效果自然好，但是因为网络分区会存在脑裂现象，这个时候使用Paxos协议依然能够保证最终决策出一个值。</li>
</ul>
<h4 id="u7B97_u6CD5_u63A8_u5BFC_u8FC7_u7A0B_uFF1A"><a href="#u7B97_u6CD5_u63A8_u5BFC_u8FC7_u7A0B_uFF1A" class="headerlink" title="算法推导过程："></a>算法推导过程：</h4><ol>
<li><p>如果我们的系统里面只有一个acceptor，那acceptor就选择它接收到的第一个proposal作为chosen value就可以了，但是这样显然存在单点故障问题。</p>
</li>
<li><p>这个时候就要考虑发给多机。如果是发给全部的节点，这样会退化成两阶段提交，可用性下降。这个时候就选择用majority的节点来完成，因为任何两个majority必然有一个相同的acceptor，由于每个acceptor只接收一个值，因此只有一个proposal能够得到majority，保证了系统的Liveness。<br>因此我们先得到一个约束：<br>P1. An acceptor must accept the first proposal that it receives.</p>
</li>
<li><p>只有P1约束可以chosen value吗？显然不行，下面看这样一个例子：假设有两个proposal同时发起请求。<br>if 所有的请求能够定序，那我们自然能够选择确定的一个（比如第一个）达成一致。<br> else， 乱序到达，我们需要majority来接受这个proposal。此时如果有A1,A2,A3,A4,A5，5个acceptor，其中P1被A1，A2首先accept，P2被A3，A4accept，不幸的是A5挂掉了，此时全局没有majority，算法失败（何以谈safety and liveness？）。</p>
<ol>
<li><p>因此，根据3中描述的问题，能够得到结论，acceptor必须允许接受多个proposal。因此我们先对这些proposal标号（这个标号表明在全局的全序关系）。</p>
</li>
<li><p>当一个acceptpr能够接受多个proposal时，为了能够支持“基本要求”中的第二条，则必须保证所有被chosen的proposal要有相同的value。<br>P2. If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v.</p>
</li>
<li><p>批准一个value意味着多个acceptor接受了该value。因此，可以对P2进行加强。<br>P2a. If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v.(P2a：一旦一个具有value v的提案被批准（chosen），那么之后任何acceptor再次接受（accept）的提案必须具有value v。)</p>
</li>
<li><p>为了维护P1，由于通信时异步的，我们可以考虑有如下场景，一个acceptor c从来没有参与过投票，而其他acceptors已经chosen一个proposal P，此时如果又有一个proposer发出一个Proposal Q，正好发给c，根据P1，c必须接受Q，但是P和Q有不同的value值，违反了P2a，因此我们需要继续对P2a进行约束。<br>P2b. If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposal proposal has value v.</p>
</li>
<li><p>由于P2b不好实现，因此提出了一个更强的约束。<br>我们要保证的是如果v被chosen，以后任何proposal只能是v。这就要求但凡有一个（n，v）能提出来，则要不就是之前从来没有value被chosen，那现在chosen什么样的值都不违背P2b，要不就是之前已经chosen，但是是标号小于n的最大proposal number里面包含v。<br>P2c. For any v and n, if a proposal with value v ad number n is issued, the there is a set S consisting of a majority of acceptors such that either (a) no acceptors in S has accepted any proposal numbered less than n, or (b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S.<br>假设具有value v的提案m获得批准，当n=m+1时，采用反证法，假如提案n不具有value v，而是具有value w，根据P2c，则存在一个多数派S1，要么他们中没有人接受过编号小于n的任何提案，要么他们已经接受的所有编号小于n的提案中编号最大的那个提案是value w。由于S1和通过提案m时的多数派C之间至少有一个公共的acceptor，所以以上两个条件都不成立，导出矛盾从而推翻假设，证明了提案n必须具有value v；<br>再做一个略形式化的证明，采用反证法<br>若（m+1）..（N-1）所有提案都具有value v，采用反证法，假如新提案N不具有value v，而是具有value w’,根据P2c，则存在一个多数派S2，要么他们没有接受过m..（N-1）中的任何提案，要么他们已经接受的所有编号小于N的提案中编号最大的那个提案是value w’。由于S2和通过m的多数派C之间至少有一个公共的acceptor，所以至少有一个acceptor曾经接受了m，从而也可以推出S2中已接受的所有编号小于n的提案中编号最大的那个提案的编号范围在m..（N-1）之间，而根据初始假设，m..（N-1）之间的所有提案都具有value v，所以S2中已接受的所有编号小于n的提案中编号最大的那个提案肯定具有value v，导出矛盾从而推翻新提案n不具有value v的假设。根据数学归纳法，我们证明了若满足P2c，则P2b一定满足。</p>
</li>
<li><p>为了维护P2c，一个标号为n的proposal必须学习小于n的已经被chosen的最大的proposal-numbered对应的v，而这个值被chosen可能是已经发生了，也可能是将要发生（因为通信异步，还有一些acceptor没有给出答案），如果学习已经确定的这很简单（majority中肯定有），但是如果学习将来要chosen的比较难，因此这个地方又做了一个限制。<br>The proposer requests that the acceptors not accept any more proposals numbered less than n.<br>P1a. An acceptor can accept a proposal numbered n iff it has not responded to a prepare request having a number greater than n.</p>
<p>整理一下上述证明过程，能够得到的结果如下：</p>
</li>
</ol>
</li>
</ol>
<h4 id="u7B97_u6CD5_u63CF_u8FF0"><a href="#u7B97_u6CD5_u63CF_u8FF0" class="headerlink" title="算法描述"></a>算法描述</h4><p>prepare阶段：</p>
<ul>
<li>proposer选择一个提案编号n并将prepare请求发送给acceptors中的一个多数派</li>
<li>acceptor收到prepare消息后，如果当前的编号大于它已经回复的所有prepare消息，则acceptor将自己上次接受的提案回复给proposer，并承诺不再回复小于n的提案</li>
</ul>
<p>批准阶段：</p>
<ul>
<li>当一个proposer收到了多数acceptors对prepare恢复后，就进入批准阶段。他要向acceptors发送accept请求，包括编号n和根据P2c决定的value，如果根据P2c没有已经接受的value，那么它可以自由决定value</li>
<li>在不违背自己向其他proposer的承诺的前提下，acceptor收到acceptor请求后即回复这个请求。<br>（阶段1和阶段2所请求的acceptors可以不同）</li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-18T13:31:15.000Z"><a href="/2014/05/18/distributed_memcache/">2014-05-18</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/18/distributed_memcache/">Distributed_memcache</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Distributed_Memory_Cache"><a href="#Distributed_Memory_Cache" class="headerlink" title="Distributed Memory Cache"></a>Distributed Memory Cache</h2><ul>
<li><p>memcached</p>
</li>
<li><p>redis</p>
</li>
</ul>
<p>本文主要总结了memcached和redis两种分布式缓存，两者的实现和Consistent Hash方面的实现。最终给出一个<br>memcached和redis之间的区别。</p>
<h2 id="Memcached"><a href="#Memcached" class="headerlink" title="Memcached"></a>Memcached</h2><ul>
<li>Free &amp; open source, high-performance, distributed memory object caching system.但是其实memcached<br>并没有实现分布式的集群设置，在server端没有实现key值的分布，需要在客户端自己设计逻辑实现。最简单的key值<br>分布是通过hash函数。采用hash函数进行key值分布，当有新节点加入或者已经存在的actived节点需要退出<br>整个集群时，整个hash函数会发生改变，导致整个key值在集群中重新分布，网络开销大。</li>
<li>97年有大神（论文<br>以后我再找）提出了Consistent Hash. 在客户端采用Consistent Hash算法进行key值的分发，计算出当前key<br>在哪个机器上存取后，直接和该及其通信，完成key-value的读写。</li>
<li><p>现在主流的memcached的Java客户端是:</p>
<ul>
<li><p>memcached-java-client</p>
</li>
<li><p>spymemcached</p>
</li>
<li><p>xmemcached</p>
</li>
</ul>
<p>三者的比较在网上比比皆是。总之memcached-java-client比较稳定，但是后两者采用nio的IO方式，效率更高。</p>
</li>
</ul>
<h2 id="Consistent_Hash"><a href="#Consistent_Hash" class="headerlink" title="Consistent Hash"></a>Consistent Hash</h2><ul>
<li>Consistent Hash中路由表的算法</li>
<li>虚拟节点</li>
</ul>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ul>
<li>Redis用作缓存也非常常见，相比于memcached主要优势在于：</li>
<li>有更加丰富的数据结构，memcached的value虽然支持序列化，但是每次修改时都要将所有的value取回然后更改之后再put回去，网络开销大。</li>
<li>Redis可以同步到硬盘，数据可靠性更强，这也是它能称之为内存数据库的一个原因吧。</li>
<li>Redis在数据量比较小的情况下，performance要比memcached好。</li>
<li><p>当然redis的single-thread的模型确实有一些问题，但是内存的性能非常高，而且从一个帖子上看到，单线程也减少了对锁的考虑</p>
<p>综合以上原因，redis越来越受到人们的欢迎。</p>
</li>
<li>同样，Redis来作Distributed memcache时，也需要做一些优化。虽然redis现在已经开始支持redis sharding cluster，但是看了设计之后，个人感觉现在server端的设计还很不完善，自发现的机制在可靠性，一致性方面都有一些问题。而且key值的分布也是通过广播的方式告诉其他节点。客户端无论发请求到哪个节点，都可以访问到一个key的range和机器的对应，当然客户端也可以通过缓存这部分数据来实现更好的性能。</li>
<li>面对并不是很完善的设计，还是从客户端来实现更优秀，Jedis提供了一个consistent hash的实现，ShardedJedisPool, ShardedJedis可以方便在客户端进行数据的分发。</li>
</ul>
<hr>
<ul>
<li>邮件(zszhaoshengzs@163.com)</li>
</ul>
<hr>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-02-19T02:53:58.000Z"><a href="/2014/02/19/build_hadoop_hbase/">2014-02-19</a></time>
      
      
  
    <h1 class="title"><a href="/2014/02/19/build_hadoop_hbase/">在Hadoop上搭建HBase</a></h1>
  

    </header>
    <div class="entry">
      
        <p>安装Hbase需要HDFS的支持，因此在搭建HBase集群首先应该搭建Hadoop集群。<br>两者的版本需要匹配，才能正常通信。<br>可以在Hadoop和Hbase的[选择]（<a href="http://hbase.apache.org/book.html#hadoop）中具体查看。" target="_blank" rel="external">http://hbase.apache.org/book.html#hadoop）中具体查看。</a></p>
<p>安装环境：</p>
<p>Hadoop-2.2.0，Hadoop Yarn稳定版</p>
<p>Hbase-0.96.1,与上述Hadoop版本匹配</p>
<p>1.安装Hadoop，在网上可以任意搜到相关教程，在配置中需要特别关注core-site.xml中fs.default.name配置项，再Hbase中会使用到该配置项。</p>
<p>2.安装Hbase，首先下载Hbase相关版本并解压</p>
<ul>
<li><p>编辑/hbase/conf/hbase-env.sh</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_OPTS=<span class="string">"$HBASE_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode"</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java-<span class="number">6</span>-openjdk-amd64</span><br><span class="line">export HBASE_MANAGES_ZK=<span class="keyword">true</span></span><br><span class="line">export HBASE_HOME=自定义的Hbase的路径</span><br></pre></td></tr></table></figure>
</li>
<li><p>编辑/hbase/conf/hbase-site.sh</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;hdfs://hadoop-master:9000/hbase(与Hadoop中HDFS的端口号相关，注意匹配)&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;hbase.master&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;192.168.7.115:60000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;192.168.7.105,192.168.7.102,192.168.7.104（slave节点）&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>编辑/hbase/conf/regionservers</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">192.168</span>.7.105</span><br><span class="line"><span class="number">192.168</span>.7.104</span><br><span class="line"><span class="number">192.168</span>.7.102</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后讲所有配置拷贝到各个slave节点</p>
</li>
<li><p>先启动hdfs，再启动hbase</p>
</li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-01-30T16:36:10.000Z"><a href="/2014/01/31/Happy Chinese New Year/">2014-01-31</a></time>
      
      
  
    <h1 class="title"><a href="/2014/01/31/Happy Chinese New Year/">2014 新年快乐</a></h1>
  

    </header>
    <div class="entry">
      
        <p>  2013年一转眼就过去了，我不是个文艺青年，不想感叹时间的流逝。只是真的觉得时间过得飞快。2013年，总觉得伴随着各种各样的紧张，暑假只回家两天，实习天天加班，老板也觉得我没有到预期的效果，天天在实验室的时间很长，但是没什么成果。但是也有很多好事情是值得鼓励和回味的，第一次和妹子的旅行发生这一年，大学毕业发生在这一年，新的开始也从这一年慢慢展开。</p>
<p>  2014年，自己需要多一些自信，多一点规划，有自己的主见，做一个有<em>担当</em>的人，说实话做到有担当并不容易。新年的规划有什么呢：</p>
<ol>
<li>生活：</li>
</ol>
<ul>
<li>尽量再旅行一次，哪怕只是很近的一个地方；</li>
<li>情人节前后一定要去一次世贸天阶，答应妹子的事情一直没有完成；</li>
<li>学习摄影，不能做无聊的人；</li>
<li>争取多点时间回家陪陪父母，春晚的《时间去哪儿了》有感触；</li>
<li>要做个有担当的人。</li>
</ul>
<ol>
<li>生活附：</li>
</ol>
<ul>
<li>妹子说工作和生活不能放在一起，但是我总觉的代码对于我来说应该算作一部分，因为我觉得我现在真的开始有点喜欢做我现在做的事情了；她看到肯定会说我是diaosi</li>
<li>深入学习一门技术，我觉得Java的多线程值得我研究研究；</li>
<li>继续搞搞我的数据库；</li>
<li>还有俺的diaosi应用</li>
</ul>
<ol>
<li>学习：</li>
</ol>
<ul>
<li>连连Leetcode</li>
<li>发篇B类会议的Paper</li>
</ul>
<p>往往计划是件非常扯淡的事情，但是还是希望能对我有点作用。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/Distributed-System/">Distributed_System</a><small>2</small></li>
  
    <li><a href="/categories/nosql/Distributed-System/">Distributed_System</a><small>1</small></li>
  
    <li><a href="/categories/nosql/">nosql</a><small>2</small></li>
  
    <li><a href="/categories/杂计/">杂计</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/DHT/">DHT</a><small>1</small></li>
  
    <li><a href="/tags/Distributed-System/">Distributed System</a><small>3</small></li>
  
    <li><a href="/tags/Paxos/">Paxos</a><small>1</small></li>
  
    <li><a href="/tags/memcache/">memcache</a><small>1</small></li>
  
    <li><a href="/tags/nosql/">nosql</a><small>1</small></li>
  
    <li><a href="/tags/tech/">tech</a><small>1</small></li>
  
    <li><a href="/tags/新年/">新年</a><small>1</small></li>
  
    <li><a href="/tags/计划/">计划</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2016 ShengZhao
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>